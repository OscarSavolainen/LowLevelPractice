{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxHNJIuUrU9Y",
        "outputId": "6471f441-1d95-4f15-84a2-eceb0edf0661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-up2i43nx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-up2i43nx\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 781ff5b76ba6c4c2d80dcbbec9983e147613cc71\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S9rm-_dsV3O",
        "outputId": "d4bbefe5-83bb-44c8-a8dc-c96b1b880605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source files will be saved in \"/tmp/tmpmop9gnrk\".\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLBddhTWxkBG",
        "outputId": "608f8256-3cbb-4ddf-b0ca-b4e9f30cad92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello from block: 1, thread: 0\n",
            "Hello from block: 1, thread: 1\n",
            "Hello from block: 0, thread: 0\n",
            "Hello from block: 0, thread: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3-nm3TUzHoA",
        "outputId": "d50fb5a3-49c8-4f7d-c22a-7dd5b4548cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100 \n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <numeric>\n",
        "#include <stdio.h>\n",
        "#include <typeinfo>\n",
        "\n",
        "__global__ void vectorAdd(float *a, float *b, float *c) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    //printf(\"%u\", a);\n",
        "    c[i] = a[i] + b[i];\n",
        "    //printf(\"%u from %u\", c[i], i);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    dim3 blocksPerGrid(2,1,1);\n",
        "    dim3 threadsPerBlock(256,1,1);\n",
        "\n",
        "    int size = 50;\n",
        "\n",
        "    std::vector<float> a(size);\n",
        "    std::vector<float> b(size);\n",
        "    std::vector<float> c(size);\n",
        "\n",
        "    std::iota(a.begin(), a.end(), 1.0f);\n",
        "    std::iota(b.begin(), b.end(), 1.0f);\n",
        "\n",
        "    float* a_dev;\n",
        "    float* b_dev;\n",
        "    float* c_dev;\n",
        "\n",
        "    //cudaMalloc((void**)&a_dev, size * sizeof(float));\n",
        "\n",
        "    cudaMalloc((void**)&a_dev, size * sizeof(float));\n",
        "    cudaMalloc((void**)&b_dev, size * sizeof(float));\n",
        "    cudaMalloc((void**)&c_dev, size * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(a_dev, a.data(), size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(b_dev, b.data(), size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(a_dev, b_dev, c_dev);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(c.data(), c_dev, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    for (const auto& value : c) {\n",
        "        std::cout << value << \" \";\n",
        "    }\n",
        "\n",
        "    cudaFree(a_dev);\n",
        "    cudaFree(b_dev);\n",
        "    cudaFree(c_dev);\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void conv2d(int *input, int *kernel, int *output) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int i_h;\n",
        "    int i_w;\n",
        "\n",
        "    int output_index = y * 3 + x;\n",
        "\n",
        "    if (output_index > 8) {\n",
        "        printf(\"Problem\");\n",
        "    } \n",
        "\n",
        "\n",
        "\n",
        "    //printf(\"%u\", input[output_index]);\n",
        "\n",
        "    for (int h = 0; h < 3; ++h) {\n",
        "        for (int w = 0; w < 3; ++w) {\n",
        "            // We get the indices for the input image, from the kernel and output indices\n",
        "            i_h = y - 1 + h;\n",
        "            i_w = x - 1 + w;\n",
        "\n",
        "            if (i_h > 0 && i_h < 3 && i_w >0 && i_w < 3) {\n",
        "              int input_index = i_h * 3 + i_w;\n",
        "              output[output_index] += input[input_index] * kernel[h * 3 + w];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    //printf(\"%u\", output[output_index]);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "\n",
        "    dim3 blocksPerGrid(1,1,1);\n",
        "    dim3 threadsPerBlock(3, 3, 1);\n",
        "\n",
        "    int kernel_size = 3;\n",
        "\n",
        "    int input[3][3] = {\n",
        "        {0, 1, 2},\n",
        "        {3, 4, 5},\n",
        "        {6, 7, 8},\n",
        "    };\n",
        "    int kernel[3][3] = {\n",
        "        {0, 0, 0},\n",
        "        {1, 1, 1},\n",
        "        {-1, -1, -1},\n",
        "    };\n",
        "\n",
        "    int output[3][3] = {0};\n",
        "\n",
        "    int* input_dev;\n",
        "    int* kernel_dev;\n",
        "    int* output_dev;\n",
        "\n",
        "\n",
        "    cudaMalloc((void**)&input_dev, 9 *sizeof(int));\n",
        "    cudaMalloc((void**)&kernel_dev, 9 *sizeof(int));\n",
        "    cudaMalloc((void**)&output_dev, 9 *sizeof(int));\n",
        "\n",
        "    cudaMemcpy(input_dev, input, 9*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(kernel_dev, kernel, 9*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    conv2d<<<blocksPerGrid, threadsPerBlock>>>(input_dev, kernel_dev, output_dev);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(output, output_dev, 9 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < 3; ++i) {\n",
        "        for (int j = 0; j < 3; ++j) {\n",
        "            std::cout << output[i][j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaFree(input_dev);\n",
        "    cudaFree(kernel_dev);\n",
        "    cudaFree(output_dev);\n",
        "    return 0;\n",
        "\n",
        "}\n",
        "    \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
